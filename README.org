#+LaTeX_HEADER:\usepackage[margin=2cm]{geometry}
#+LaTeX_HEADER:\usepackage{enumitem}
#+LaTeX_HEADER:\renewcommand{\ttdefault}{pcr}
#+LaTeX_HEADER:\lstdefinelanguage{yaml}{basicstyle=\ttfamily\scriptsize,frame=lrtb,framerule=1pt,framexleftmargin=1pt,showstringspaces=false}
#+LaTeX_HEADER:\usepackage{etoolbox}
#+LaTeX_HEADER:\makeatletter\patchcmd{\@verbatim}{\verbatim@font}{\verbatim@font\scriptsize}{}{}\makeatother
#+LATEX:\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
#+OPTIONS: toc:nil author:nil ^:nil

#+TITLE: L7MP: A L7 Multiprotocol Proxy and Service Mesh

/[L7mp is currently under construction, with many advertised features untested, not working as promised, or completely missing.]/

L7mp is a Layer-7, multiprotocol service proxy and a service mesh framework.  The main
characteristics is emphasis on "L7", because the main unit of traffic is transport- and
application-layer connections/sessions, and "multiprotocol" support, in order to handle as many
network protocol encapsulations as possible beyond TCP/HTTP. The main intention of the L7mp project
is to server as an incubator and a testbed for a set of useful extensions that should eventually be
implemented into major service mesh frameworks in order to support legacy non-HTTP applications
seamlessly.

The distribution contains an /l7mp proxy/ component, which can programatically stitch
application-level traffic streams together into an end-to-end stream in a protocol-agnostic manner
(e.g., you can pipe a UNIX domain socket to a WebSocket stream transparently and vice versa) and an
/l7mj service mesh/, a Kubernetes operator that can program and manage a legion of L7mp gateway and
sidecar proxy instances via a RESTful API based on a set of high-level Kubernetes custom resources.

** The L7mp proxy

The L7mp proxy is modeled after [[https://github.com/envoyproxy/envoy][Envoy]] in that it uses similar abstractions (Listeners, Clusters,
etc.), but in contrast to Envoy that is HTTP/TCP centric l7mp is optimized for persistent,
long-lived UDP-based media and tunneling protocol streams. The L7mp proxy features an extended
routing API, which allows to transparently pipe sessions across diverse protocol encapsulations,
with automatic and transparent protocol transformation (e.g., you can route a UDP listener or a raw
IP socket to a WebSocket cluster and everything should work as expected), native support for
datagram- and byte-streams, stream multiplexing/demultiplexing, encapsulation/decapsulation, etc.

Considering the strong emphasis on multiprotocol support, the L7mp proxy may actually be closer in
nature to =socat(1)= than to Envoy, but it is dynamically configurable via a REST API in contrast
to =socat(1)= which is a static CLI tool (but =socat= it is much more feature-complete than L7mp in
return).

The L7mp proxy is written in Javascript/Node.js. This way, it is much simpler and easier to extend
than Envoy or =socat=, but at the same time it is also much slower. It does not have to be that way
though; an XDP/ebpf-based proxy-acceleration framework is under construction that would enable l7mp
to run at hundreds of thousands of packets per second.

** The l7mp service mesh

The l7mp distribution contains a Kubernetes operator that makes it possible to deploy and manage
the l7mp proxies as a sidecar proxy and a gateway in a Kubernetes cluster in a service-mesh-like
framework. This allows to configure the advanced networking capabilities enjoying the convenience
of a high-level Kubernetes API. The operator is currently under construction, more details to
follow soon.

* Installation

The below should eventually work fine, once L7mp gets open-sourced.

#+BEGIN_SRC sh
npm install l7mp --save
#+END_SRC

Until then, use the enclosed Dockerfile to deploy L7mp. At least Node.js v14 is needed.

* Usage example

** Run

Run L7mp locally with a [[https://github.com/rg0now/l7mp/blob/master/config/l7mp-simple.yaml][sample]] static configuration.

#+BEGIN_SRC sh
node l7mp-proxy.js -c config/l7mp-minimal.yaml -l warn
#+END_SRC

Configuration is accepted either in YAML format (if the extension is =.yaml=) or JSON (otherwise).
Command line arguments override static configuration parameters.

** Query configuration

The sample configuration will fire up a HTTP listener at port 1234 and route it to the L7mp
controller that serves the L7mp REST API.  This API can be used to query or configure the proxy on
the fly; e.g., the below will dump the full current configuration back in JSON format:

#+BEGIN_SRC sh
curl http://localhost:1234/api/v1/config
#+END_SRC

** Manage sessions

On top of the static configuration, the response contains a new =sessions= list that enumerates the
set of active (connected) live sessions in L7mp.  You can list the live sessions explicitly.

#+BEGIN_SRC sh
curl http://localhost:1234/api/v1/sessions
#+END_SRC

You should see only a single HTTP session by default: this session was created by the L7mp proxy
to route the REST API query from the HTTP listener to the controller cluster and this session
happens to be active when the session list is requested.

You can delete any session (suppose its name is =session-name=) via the below REST API call.

#+BEGIN_SRC sh
curl -iX DELETE http://localhost:1234/api/v1/sessions/<session-name>
#+END_SRC

** Add a new cluster

Add a new UDP cluster named =user-1-2-c= that will connect to the endpoint at =localhost:16000=,
and bind this cluster locally to port 16001.

#+BEGIN_SRC sh
curl -iX POST --header 'Content-Type:text/x-yaml' --data-binary @- <<EOF  http://localhost:1234/api/v1/clusters
cluster:
  name: user-1-2-c
  spec: { protocol: "UDP", port: 16000, bind: { address: '127.0.0.1', port: 16001 } }
  endpoints:
    - spec: { address:  "127.0.0.1" }
EOF
#+END_SRC

Note that the REST API accepts both JSON and YAML configs (YAML will be converted to JSON
internally). If multiple endpoints are added, L7mp will load-balance among these (TODO, currently
only the =trivial= load balancer is implemented that routes everything to the first endpoint).

** Add a new listener with a route

Now add a new UDP listener called =user-1-2-l= at port 15000 that will immediately connect back to
=127.0.0.1:15001= and route it to the cluster we have just created (named =user-1-2-c=).

#+BEGIN_SRC sh
curl -iX POST --header 'Content-Type:text/x-yaml' --data-binary @- <<EOF  http://localhost:1234/api/v1/listeners
listener:
  name: user-1-2-l
  spec: { protocol: UDP, port: 15000, connect: {address: "127.0.0.1", port: 15001} }
  rules:
    - action:
        route:
          destination: user-1-2-c
          ingress:
            - spec: { protocol: Logger }
          retry: {retry_on: always, num_retries: 3, timeout: 2000}
EOF
#+END_SRC

There is an important quirk here. The =route= in the above specifies a new cluster embedded into
the route definition (the one with the protocol =Logger=); this is a special transport cluster that
will instruct l7mp to log all traffic arriving from the listener to the standard output. Of course,
we could have added this cluster in a separate REST API call as we did above:

#+BEGIN_SRC sh
curl -iX POST --header 'Content-Type:text/x-yaml' --data-binary @- <<EOF  http://localhost:1234/api/v1/clusters
cluster:
  name: logger
  spec: { protocol: "Logger" }
EOF
#+END_SRC

#+BEGIN_SRC sh
curl -iX POST --header 'Content-Type:text/x-yaml' --data-binary @- <<EOF  http://localhost:1234/api/v1/listeners
listener:
  name: user-1-2-l
  spec: { protocol: UDP, port: 15000, connect: {address: "127.0.0.1", port: 15001} }
  rules:
    - action:
        route:
          destination: user-1-2-c
          ingress:
            - logger
          retry: {retry_on: always, num_retries: 3, timeout: 2000}
EOF
#+END_SRC

And then let the new listener refer to this cluster by name. This flexibility of the l7mp proxy to
accept explicit and implicit (embedded) configurations is available in essentially all REST API
calls and greatly simplifies the use of the configuration API.

** Routing

On session creation, L7mp will demultiplex the bidirectional stream at the listener into two
uni-directional streams: the /ingress stream/ (in the direction from the listener to the cluster)
will be routed through the WebSocket =Logger= cluster, which may then readily transform the stream
and send the results back.  The returned stream is then piped to the cluster =user-1-2-c=.  In the
/egress direction/ (from the cluster back to the listener), no transformation occurs.

The ingress and the egress routes are specified and handled separately.  Both routes can contain a
list of any number of Transform clusters that will be chained sequentially, automatically
performing transparent protocol and payload conversion along the way. Note that datagram boundaries
are preserved during transformation whenever possible, and when it is not (i.e., piping a UDP
stream to a TCP cluster will lose segmentation), L7mp issues a warning.

This should yield the routes:

: ingress: user-1-2-l -> up -> user-1-2-c
: egress:  user-1-2-c -> user-1-2-l

When created, the UDP listener immediately becomes connected (to avoid this behavior, do not
specify a =connect= clause in the spec), creates a session, and then tries to route the session
through the =Logger= cluster by properly piping the underlying streams.

** Retries and timeouts

Route specifications can contain a =retries=, in order to describe what to do if one of the
connected clusters fail. By the above spec, L7mp will automatically retry the connection at most
200 times, waiting each time 1000 ms for the stream to be successfully established.

** Test the connection

To complete the connection, fire up a =socat= sender (don't forget to bind the sender to 15001,
otherwise L7mp, which connects back to this port, will not accept the connection):

#+BEGIN_SRC sh
socat - udp:localhost:15000,sourceport=15001
#+END_SRC

Then, start a =socat= receiver:

#+BEGIN_SRC sh
socat udp-l:16000 -
#+END_SRC

What you type in the sender should appear transparently at the receiver and the l7mp prxy should
report everything that passes from the sender to the receiver but nothing in the reverse direction,
since the =Logger= was added to the /ingress chain/ but not to the /egress chain/.

** Clean up

Provided that the new session is named =session-name= (L7mp automatically assigns unique names to
each session, you can check this by issuing a GET request to the API endpoint
=/api/v1/sessions/{session-name}=), you can delete the session, the cluster and the listener as
follows:

#+BEGIN_SRC sh
curl -iX DELETE http://localhost:1234/api/v1/sessions/<session-name>
curl -iX DELETE http://localhost:1234/api/v1/listeners/user-1-2-l
curl -iX DELETE http://localhost:1234/api/v1/clusters/user-1-2-c
#+END_SRC

NB: the rulelist, rule, and the route created by the listener will not be removed by the above, but
this should make no harm.

* Protocol support

|------------------+-------------------+-----------------+------+------------------+---------+---------|
| Protocol         | Session ID        | Type            | Role | Mode             | Re/Lb   | Status  |
|------------------+-------------------+-----------------+------+------------------+---------+---------|
| UDP              | IP 5-tuple        | datagram-stream | l/c  | singleton/server | yes/yes | Full    |
| TCP              | IP 5-tuple        | byte-stream     | l/c  | server           | yes/yes | Full    |
| HTTP             | IP 5-tuple        | byte-stream     | l    | server           | yes/yes | Partial |
| WebSocket        | IP 5-tuple + HTTP | datagram-stream | l/c  | server           | yes/yes | Full    |
| STDIO-fork       | N/A               | byte-stream     | c    | singleton        | no/no   | Full    |
| UNIX/stream      | file desc/path    | byte-stream     | l/c  | server           | yes/yes | Full    |
| UNIX/dgram       | file desc/path    | datagram-stream | l/c  | singleton        | no/no   | TODO    |
| PIPE             | file desc/path    | byte-stream     | l/c  | singleton        | no/no   | TODO    |
| AF_PACKET        | file desc         | datagram-stream | l/c  | singleton        | no/no   | TODO    |
| INLINE/STDIO     | N/A               | byte-stream     | c    | singleton        | yes/no  | Full    |
| INLINE/Echo      | N/A               | datagram-stream | c    | singleton        | yes/no  | Full    |
| INLINE/Discard   | N/A               | datagram-stream | c    | singleton        | yes/no  | Full    |
| INLINE/Logger    | N/A               | datagram-stream | c    | singleton        | yes/no  | Full    |
| INLINE/JSONENcap | N/A               | datagram-stream | c    | singleton        | yes/no  | Full    |
| INLINE/JSONDecap | N/A               | datagram-stream | c    | singleton        | yes/no  | Full    |
|------------------+-------------------+-----------------+------+------------------+---------+---------|

** Protocols

- UDP "singleton mode" is a "connected" UDP server, while UDP "server mode" is a listener-only
  protocol that emits a new session for each packet received with a new IP 5-tuple
- STDIO-fork is a (transform-only) protocol for communicating with a forked process through
  STDIO/STDOUT
- Inline/STDIO pipes the stream to the L7mp proxy stdin/stdout, stream reads from stdin and write
  to stdout (useful for debugging)
- Inline/Echo is an Echo Cluster, writes back everything it reads (useful for debugging)
- Inline/Discard is blackholes everyting it received (useful for debugging)
- Inline/Logger is like an Echo Cluster, but it also writes everything that goes through it to a
  file or to the standard output (useful for debugging)

** Session id

A unique name/descriptor for a session, generated dynamically by the protocol's listener.

** Type

- byte-stream: segmentation/message boundaries not preserved
- datagram-stream segmentation/message boundaries preserved

Note that streams can run on top of datagram protocols but not the other way around; l7mp warns
when such a conversion is requested.

** Mode

- server: listen+accept -> new session
- singleton: can emit a single session only

** Role

- listener (l): protocol supports listeners to emit sessions
- cluster (c): protocol supports clusters to forward sessions to

** Re/To/Lb

- Re: Retries support, To: Timeout support, Lb: load-balance support

** Status

* Documentation

- [[https://github.com/rg0now/l7mp/blob/master/doc/README.md][API model]] and the REST API [[https://github.com/rg0now/l7mp/blob/master/openapi/index.html][endpoints]]
- Main [[https://github.com/rg0now/l7mp/blob/master/openapi/README.md][concepts]]

* License

Copyright 2019-2020 by its authors.  Some rights reserved. See AUTHORS.

MIT License
